{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33ced95-adae-46f0-ad56-573832e0b995",
   "metadata": {},
   "source": [
    "# **spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd65500-3f0f-4bb1-9111-dc5000e0c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlheller/home/Technical/repos/dft/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d98ab3-0bd5-4dde-90e0-33f2506b8516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My my\n",
      "name name\n",
      "is be\n",
      "Shaurya Shaurya\n",
      "Uppal Uppal\n",
      ". .\n",
      "I I\n",
      "enjoy enjoy\n",
      "writing write\n",
      "\n",
      "\t\t \n",
      "\t\t\n",
      "articles article\n",
      "on on\n",
      "GeeksforGeeks GeeksforGeeks\n",
      "checkout checkout\n",
      "my my\n",
      "other other\n",
      "\n",
      "\t\t \n",
      "\t\t\n",
      "article article\n",
      "by by\n",
      "going go\n",
      "to to\n",
      "my my\n",
      "profile profile\n",
      "section section\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load(\"en_core_web_md\") \n",
    "\n",
    "# Process whole documents \n",
    "text = (\"\"\"My name is Shaurya Uppal. I enjoy writing \n",
    "\t\tarticles on GeeksforGeeks checkout my other \n",
    "\t\tarticle by going to my profile section.\"\"\") \n",
    "\n",
    "doc = nlp(text) \n",
    "\n",
    "for token in doc: \n",
    "    print(token, token.lemma_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597c9396-a155-42a4-ba75-0496aa132a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My PRON\n",
      "name NOUN\n",
      "is AUX\n",
      "Shaurya PROPN\n",
      "Uppal PROPN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "I PRON\n",
      "enjoy VERB\n",
      "writing VERB\n",
      "articles NOUN\n",
      "on ADP\n",
      "GeeksforGeeks PROPN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "My PRON\n",
      "father NOUN\n",
      "enjoys VERB\n",
      "reading VERB\n",
      "my PRON\n",
      "articles NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "There PRON\n",
      "are VERB\n",
      "many ADJ\n",
      "articles NOUN\n",
      "of ADP\n",
      "mine NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Checkout PROPN\n",
      "\n",
      " SPACE\n",
      "my PRON\n",
      "other ADJ\n",
      "article NOUN\n",
      "by ADP\n",
      "going VERB\n",
      "to ADP\n",
      "my PRON\n",
      "profile NOUN\n",
      "section NOUN\n",
      ". PUNCT\n",
      "Verbs: ['enjoy', 'writing', 'enjoys', 'reading', 'are', 'going']\n",
      "Verbs: ['enjoy', 'write', 'enjoy', 'read', 'be', 'go']\n"
     ]
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, \n",
    "# parser, NER and word vectors \n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Process whole documents \n",
    "text = (\"\"\"My name is Shaurya Uppal. \n",
    "I enjoy writing articles on GeeksforGeeks.\n",
    "My father enjoys reading my articles.\n",
    "There are many articles of mine.\n",
    "Checkout \n",
    "my other article by going to my profile section.\"\"\") \n",
    "\n",
    "doc = nlp(text) \n",
    "\n",
    "# Token and Tag \n",
    "for token in doc: \n",
    "    print(token, token.pos_) \n",
    "\n",
    "# You want list of Verb tokens \n",
    "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"]) \n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
